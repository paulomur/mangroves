[["index.html", "Mapping mangroves using remote sensing 1 Overview", " Mapping mangroves using remote sensing Paulo J. Murillo-Sandoval April 13, 2021 1 Overview Mangroves play a critical role in our social, economic, and ecological resources, but there are gaps in our understanding of carbon accounting and management. This is why we use field and remote observations to monitor its status. This tutorial uses different satellite data to map the current extent of mangroves using Sentinel 1 &amp; 2 and historically using Landsat legacy. This project is funded by SilvaCarbon and the study region is Colombia. More info about other mangroves related projects https://mangrovescience.org/ (PI. Lola Fatoyinbo) Figure 1.1: Mangroves Source: Pixabay "],["mapping-mangroves-using-sentinel12.html", "2 Mapping mangroves using Sentinel1&amp;2 2.1 Preprocessing/Exporting Sentinel-1 and Sentinel-2 2.2 Organizing a basemap (get training data) 2.3 Indices and an object-based classifier", " 2 Mapping mangroves using Sentinel1&amp;2 We use Colombia as study region for this analysis. However, our analysis can be applied everywhere. The steps to map mangroves and other common land cover classes are: Pre-processing/Exporting Sentinel-1 and Sentinel-2 Organizing a basemap (get training data!!!) Applying an object-based classifier All previous steps can be easily modified for specific regions and conditions. First thing is adding the repository to your Earth Engine account: https://code.earthengine.google.com/?accept_repo=users/murillop/mapping_mangroves # and call the main library: var man = require(&#39;users/murillop/mapping_mangroves:mangroves&#39;); In that the repository you can find the main library plus the examples to run the analysis. 2.1 Preprocessing/Exporting Sentinel-1 and Sentinel-2 Preprocessing data from S1 requires the effective removal of speckle noise. We use Perona-Malik filter to remove speckle for each image. For Sentinel-2 we remove clouds and shadows. All functions allows to obtain better spectral information for the period 2019-2020. After improving the data, a image composite using the median. We also &gt; calcuate the standard deviation and percentiles 20th and 80th. Finally we save the resulting composite as an asset. The only parameter needed are: //# Import library var man = require(&#39;users/murillop/mapping_mangroves:mangroves&#39;); var region = ee.Geometry.Polygon( [[[-78.63099738574668, 2.746827033203151], [-78.63099738574668, 2.2295862108717603], [-77.70677253223106, 2.2295862108717603], [-77.70677253223106, 2.746827033203151]]], null, false); var AOI = region; //# Parameters var params = { START_DATE: &#39;2019-01-01&#39;, END_DATE: &#39;2021-01-01&#39;, CLOUD_FILTER : 60, #//CLOUDY_PIXEL_PERCENTAGE. Select less than 60% CLD_PRB_THRESH : 20, #//PROBABILITY greater than 20% NIR_DRK_THRESH : 0.15, #//For shadows CLD_PRJ_DIST : 1, #//Project shadows from clouds using distance =1 BUFFER : 50 #//Buffer around clouds }; After modify your parameters you can apply the functions needed for pre-processing Example: Get all S2 images based on parameters. var s2_sr_cld_col_eval = man.get_s2_sr_cld_col(AOI, params); print (s2_sr_cld_col_eval.size(),&#39;number of S2 images&#39;); and to apply cloud masking and shadow masking var s2 = s2_sr_cld_col_eval.map(function(img){return man.add_cld_shdw_mask(img, params)}); s2 =s2.map(function(img){return man.apply_cld_shdw_mask(img, params)}); See the rest of the script on the repository 1.Export_S1_S2_composite. 2.2 Organizing a basemap (get training data) Getting training data for a classification process is a exhausting task. Mostly visual and manually collected, training data is key for a success classification process.Here we use previous maps created by Colombia Government from which we select specific land cover classes. The basemap follows the Corine Land Cover (CLC) methodology which is the official methodology employs by official Colombian agencies. See official CLC documentation can be found here For this exercise, five classes were used: 1. Mangroves 2. Water 3. Dense Forest &gt;80% tree canopy cover 4. Non-forest &lt;20% tree canopy cover 5. Other vegetation (shurb, herbaceous, wet forest) This function add specific land cover types. var man = require(&#39;users/murillop/NASA_mangroves:mangroves&#39;); # Get Corine Land cover classes var corine = man.getCORINE() The CLC is from 2012. We update this map using Hansen and JRC datasets for 2019. This process helps to obtain classes more pure pixels, discard outliers and update them. For instance in the case of mangroves class, I updated the class taking into account the presence of water in S1 and forest/non-forest mask derived from Hansen. #Update **manglar** class when it is water and when it is non-forest. var manglar1 = corine.select(&#39;manglar&#39;) .updateMask(vv_water.eq(0)) #//remove water .updateMask(corine.select(&#39;F-NF&#39;).eq(1)) #//remove when it is non-forest .remap([0],[1]).int() .rename(&#39;class&#39;); 2.3 Indices and an object-based classifier We calculate a set of different relevant spectral metrics from the exported asset. Relevant vegetation indices and GLCM textural metrics for mapping mangroves were calculate. To add them into the exported asset. //# Read S1+S2 var s1_s2 = ee.Image(&quot;projects/mangrovescience/SilviaCarbon_COL/Sentinel_Predictors/s1_s2_2019-01-01_2021-01-01&quot;) //# Read S2 only and calculate different predictors (Indices+GLCM indicators) var s2 =s1_s2.select(&#39;B.*&#39;); s2 =man.doIndices2(ee.ImageCollection(s2)); Now we have S2 data, then we add S1 bands: var s1 =ee.Image(&quot;projects/mangrovescience/SilviaCarbon_COL/Sentinel_Predictors/s1_s2_2019-01-01_2021-01-01&quot;) .select(&#39;VV&#39;,&#39;VH&#39;); var s1s2_new = s2.addBands(s1); var bands = s1s2_new.bandNames(); print(s1s2_new, &#39;s1s2_new&#39;); Once we have our final set of predictors we can apply a object-based classifier. Object-based classifiers are more robust than conventional pixel-based analysis. We used the SNIC algorithm to detect clusters using the Mangroves Vegetation Index (MVI). See article here. User can modify MVI for any other index or metric. They current available indices are: NBR, NDVI, NDMI, MNDWI, MVI, CMRI, GLCM (8 metrics). If you want to add your a different index, you should update the main library mangroves. //# Define SNIC var snic_sen1_2 = man.snic_mangroves_sentinel(s1s2_new.select(bands), &#39;MVI&#39;); #// You can pick other index var predictionBands=snic_sen1_2.bandNames().remove(&#39;clusters&#39;); snic_sen1_2 = snic_sen1_2.select(predictionBands); "],["mapping-mangroves-using-landsat-archive.html", "3 Mapping mangroves using Landsat archive 3.1 Making fitted values using Landsat archive 3.2 Building 3-years composite maps", " 3 Mapping mangroves using Landsat archive For mapping historical mangroves change using Landsat our approach is a bit different than for S1+S2. The Colombian Pacific is the most rainy region worldwide, consequently obtain cloud-free optical data is very difficult for this region. To improve spectral data and filling gaps for missing year I employ LandTrendr. Given the lack of images we create 3-year composites from 1985-2020 that were linearly improved using temporal segmentation from Landtrendr. This Figure shows a simple way to linearly improve the original spectral data from Landsat but also filling gaps in periods in which few observations were available. This process guarantees a much spectro-temporal stability of the data that might helps to produce better land cover land use maps Figure 3.1: LandTrendr segmentation example 3.1 Making fitted values using Landsat archive Landsat is a popular satellite that aids to consistently track Earth land surface. In tropical areas clouds and lack of Landsat observations affect tracking evolution of changes. Using LandTrendr we improve Landsat itself through some steps: 3.1.1 Remove bad imagery In some cases even after removing masking out clouds, some images remain with them. Those images can affect seriously the composites we finally want. Specially in coastal areas is very common to find problems with images and other artifacts. One way to remove them is comparing original image vs cloud masking image. If clouds remains after masking, we should select the image ID and remove it from the ImageCollection. This process mainly important for early years in 80 and 90s. Given that few images are available, onyl one with problems can affect our final composite product. Using the Remove bad imagery code in the repository you can identify which ones should not be included in the process. Figure 3.2: Image with remaing clouds (left), original image (right) After you pick those images that cannot be part of the process, you can exclude using  not_contains from the code Export_Landsat var getSRcollection = function(firstYear,lastYear, startDay, endDay, sensor, box) { var srCollection = ee.ImageCollection(&#39;LANDSAT/&#39;+ sensor + &#39;/C01/T1_SR&#39;) //# get surface reflectance images .filterBounds(box) //# filter them by a bounding box .filter(ee.Filter.calendarRange(day_start,day_end,&#39;day_of_month&#39;)) .filter(ee.Filter.calendarRange(month_start,month_end,&#39;month&#39;)) .filter(ee.Filter.calendarRange(firstYear,lastYear,&#39;year&#39;)) .filterMetadata(&#39;system:index&#39;, &#39;not_contains&#39;, &#39;LT04_010059_19871113&#39;)} 3.1.2 Input parameters (1) Common parameters in LandTrendr includes the name of the task, region, years and others. In this example we use NBR as main index for segmentation and the new fitted bands will be the spectral bands from Landsat. Our outputs fitted data could be also other indices not necessarily the spectral bands. We use Medoid to create the composites but we can also used a targetDay. The code that includes all next steps is Export_Landsat var featureValues = [&#39;Man&#39;]; // Name it is useful if you want to export many different regions var featureCol = geometry; // Region to be exported var featureKey = &#39;Col&#39;; // Name 2 // it is useful if you want to export many different regions var startYear = 1985; // what year do you want to start the time series var endYear = 2020; // what year do you want to end the time series var startDay =[&#39;01-01&#39;]; // what is the beginning of date filter | month-day var endDay = [&#39;12-31&#39;]; // what is the end of date filter | month-day var indexList = [[&#39;NBR&#39;, -1, true]]; // The indices to segment on and the invert coefficient var ftvList = [&#39;B1&#39;, &#39;B2&#39;, &#39;B3&#39;, &#39;B4&#39;, &#39;B5&#39;, &#39;B7&#39;]; // List of images to export var vertList =[];// &#39;YRS&#39;, &#39;SRC&#39;, &#39;FIT&#39; var mosaicType = &quot;medoid&quot;; // how to make annual mosaic - options: &quot;medoid&quot;, &quot;targetDay&quot; var targetDay = null ; // you can use 172 here rather than null if use &quot;targetDay&quot; // if running &quot;targetDay&quot; mosaic, what day of year should be the target var outProj = &#39;EPSG:32618&#39;; // what should the output projection be? &#39;EPSG:2317&#39; for SouthAmerica var gDriveFolder = &#39;SilviaCarbon_COL&#39;//+ featureKey + &#39;_&#39; + indexList[0][0]; // what is the name of the Google Drive folder that you want the outputs placed in var affine = [30.0, 0, 15.0, 0, -30.0, 15.0]; var aoiBuffer = 30; //1 pixel This inputs can be modified to export many different regions at the same time. For instance if you have a FeatureCollection with a field called PATH_ROW and the values names are (7058,7059) you can export them individually as: var featureValues = [&#39;7058&#39;, &#39;7059&#39;]; // Name it is useful if you want to export many different regions var featureCol = yourFeatureCollection; // Region to be exported var featureKey = &#39;PATH_ROW&#39;; // Name 2 // Name of the field ... More details about this step on (https://emapr.github.io/LT-GEE/landtrendr.html) 3.1.3 Input parameters (2) LandTrendr works over annual composites. In some regions, it is possible to use annual observations however in the Colombian Pacific there is too few data. The only alternative is to increase the temporal window. In this case we use three-year composites from 1985-2020. In other words we have 12 temporal periods for tracking mangroves extent and change. This code helps to create composites every one, two or any window you want. However, if you want to change epochLen, you also have to consider changing the startYear and endYear because the epoch might not exactly match with the amount of years. In this cases our startYear = 1985, endYear=2020 and our epochLen =3 Figure 3.3: Epochs 3.1.4 Adding percentiles Medoid is a good strategy to create our composites. However, we can add more spectral information to improve classification of similar land cover classes. In the same code we add the Percentile 20, 80 and Standard Deviation. Before running the code, you must create an ImageCollection in you Earth Engine account. This Collection will host all these additional information. You can just go to Assest Tab, New, Image Collection. Once you create it you can modify the assetId name: percentil .aggregate_array(&#39;system:index&#39;) .evaluate(function (systemIndexes) { systemIndexes.forEach(function (systemIndex, i) { // print(i) // This is your 0-based index var image = percentil .filterMetadata(&#39;system:index&#39;, &#39;equals&#39;, systemIndex) .first(); var oldIndex = msToFrac(image.get(&#39;system:time_start&#39;)).int16(); //get mills to year image = image.set(&#39;composite_year&#39;, oldIndex).clip(featureCol); //print (image) Export.image.toAsset({ image: image, description: &#39;percentiles_&#39; + i, assetId: &#39;YourCollectionName/percentiles_&#39; + i, crs: outProj, scale: 30, maxPixels: 1e13, region: featureCol, }); }); }); 3.1.5 Exporting assets After you remove bad images and change parameters you can export the fitted image plus the percentiles as an ImageCollection. Given this process is very demanding computationally it might takes some minutes afte you can export the data. You should see something like this: Figure 3.4: Tasks 3.2 Building 3-years composite maps "]]
